{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint Deployment with Inference Component\n",
    "\n",
    "This notebook demonstrates how to deploy a model from SageMaker Model Registry to a SageMaker Endpoint using Inference Components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:51:52.640083Z",
     "iopub.status.busy": "2025-08-31T12:51:52.639834Z",
     "iopub.status.idle": "2025-08-31T12:51:52.642969Z",
     "shell.execute_reply": "2025-08-31T12:51:52.642492Z",
     "shell.execute_reply.started": "2025-08-31T12:51:52.640064Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import image_uris\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure SageMaker Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:51:53.995765Z",
     "iopub.status.busy": "2025-08-31T12:51:53.995505Z",
     "iopub.status.idle": "2025-08-31T12:51:54.466954Z",
     "shell.execute_reply": "2025-08-31T12:51:54.466430Z",
     "shell.execute_reply.started": "2025-08-31T12:51:53.995745Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket: sagemaker-us-east-1-637423390840\n",
      "Using region: us-east-1\n",
      "Using role: arn:aws:iam::637423390840:role/WSParticipantRole\n"
     ]
    }
   ],
   "source": [
    "# SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::637423390840:role/WSParticipantRole\" # need to change your role\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# Clients\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "# S3 Bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"qwen3-0-6-lora-samples\"\n",
    "\n",
    "print(f\"Using bucket: {bucket}\")\n",
    "print(f\"Using region: {region}\")\n",
    "print(f\"Using role: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model from Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:51:55.135676Z",
     "iopub.status.busy": "2025-08-31T12:51:55.135427Z",
     "iopub.status.idle": "2025-08-31T12:51:55.335392Z",
     "shell.execute_reply": "2025-08-31T12:51:55.334930Z",
     "shell.execute_reply.started": "2025-08-31T12:51:55.135657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Latest Approved Model ===\n",
      "Model Package ARN: arn:aws:sagemaker:us-east-1:637423390840:model-package/qwen3-0-6b-lora-models/5\n",
      "Created: 2025-08-31 12:51:29.757000+00:00\n",
      "Description: QWEN3-0.6B LoRA fine-tuned model | Training Job: qwen3-0-6b-lora-fine-tuning-lora-2025-08-31-12-28-29 | Eval Loss: 0.8944 | BLEU: 0.0528 | Samples: 15 | Timestamp: 20250831-125129\n"
     ]
    }
   ],
   "source": [
    "# Model package group name (same as used in model registry)\n",
    "model_package_group_name = \"qwen3-0-6b-lora-models\"\n",
    "\n",
    "# List approved models in the model package group\n",
    "response = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    ModelApprovalStatus='Approved',\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending',\n",
    "    MaxResults=10\n",
    ")\n",
    "\n",
    "if response['ModelPackageSummaryList']:\n",
    "    # Get the latest approved model\n",
    "    latest_model_package = response['ModelPackageSummaryList'][0]\n",
    "    model_package_arn = latest_model_package['ModelPackageArn']\n",
    "    \n",
    "    print(f\"=== Latest Approved Model ===\")\n",
    "    print(f\"Model Package ARN: {model_package_arn}\")\n",
    "    print(f\"Created: {latest_model_package['CreationTime']}\")\n",
    "    \n",
    "    # Get detailed model information\n",
    "    model_package_details = sm_client.describe_model_package(\n",
    "        ModelPackageName=model_package_arn\n",
    "    )\n",
    "    \n",
    "    if 'ModelPackageDescription' in model_package_details:\n",
    "        print(f\"Description: {model_package_details['ModelPackageDescription']}\")\n",
    "else:\n",
    "    print(\"No approved models found in the registry.\")\n",
    "    print(\"Please approve a model in the Model Registry first.\")\n",
    "    model_package_arn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Model from Model Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:51:55.848990Z",
     "iopub.status.busy": "2025-08-31T12:51:55.848742Z",
     "iopub.status.idle": "2025-08-31T12:51:56.584441Z",
     "shell.execute_reply": "2025-08-31T12:51:56.583935Z",
     "shell.execute_reply.started": "2025-08-31T12:51:55.848971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Created ===\n",
      "Model Name: qwen3-0-6b-lora-model-20250831-125155\n",
      "Model ARN: arn:aws:sagemaker:us-east-1:637423390840:model/qwen3-0-6b-lora-model-20250831-125155\n",
      "Model Data: s3://sagemaker-us-east-1-637423390840/qwen3-0-6-lora-samples/output/qwen3-0-6b-lora-fine-tuning-lora-2025-08-31-12-28-29/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "if model_package_arn:\n",
    "    # Create model name with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_name = f\"qwen3-0-6b-lora-model-{timestamp}\"\n",
    "    \n",
    "    # Option 1: Create model directly from model package (simpler)\n",
    "    try:\n",
    "        # This is the simplest way - let SageMaker handle everything from the model package\n",
    "        create_model_response = sm_client.create_model_from_model_package(\n",
    "            ModelName=model_name,\n",
    "            ModelPackageName=model_package_arn\n",
    "        )\n",
    "        print(f\"\\n=== Model Created from Model Package ===\")\n",
    "        print(f\"Model Name: {model_name}\")\n",
    "        print(f\"Model ARN: {create_model_response['ModelArn']}\")\n",
    "    except:\n",
    "        # Option 2: If the above doesn't work, extract container details manually\n",
    "        # Get container details from model package\n",
    "        model_package_details = sm_client.describe_model_package(\n",
    "            ModelPackageName=model_package_arn\n",
    "        )\n",
    "        \n",
    "        # Extract container configuration from inference specification\n",
    "        container = model_package_details['InferenceSpecification']['Containers'][0]\n",
    "        \n",
    "        # Create model from model package\n",
    "        create_model_response = sm_client.create_model(\n",
    "            ModelName=model_name,\n",
    "            ExecutionRoleArn=role,\n",
    "            PrimaryContainer={\n",
    "                'Image': container['Image'],\n",
    "                'ModelDataUrl': container['ModelDataUrl'],\n",
    "                'Environment': container.get('Environment', {})\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n=== Model Created ===\")\n",
    "        print(f\"Model Name: {model_name}\")\n",
    "        print(f\"Model ARN: {create_model_response['ModelArn']}\")\n",
    "        print(f\"Model Data: {container['ModelDataUrl']}\")\n",
    "else:\n",
    "    print(\"Cannot proceed without a model package ARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Endpoint Configuration with Inference Component Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:51:56.585349Z",
     "iopub.status.busy": "2025-08-31T12:51:56.585166Z",
     "iopub.status.idle": "2025-08-31T12:51:56.977279Z",
     "shell.execute_reply": "2025-08-31T12:51:56.976705Z",
     "shell.execute_reply.started": "2025-08-31T12:51:56.585333Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Endpoint Configuration Created ===\n",
      "Config Name: qwen3-0-6b-lora-config-20250831-125155\n",
      "Config ARN: arn:aws:sagemaker:us-east-1:637423390840:endpoint-config/qwen3-0-6b-lora-config-20250831-125155\n",
      "Instance Type: ml.g5.2xlarge\n",
      "Initial Instance Count: 1\n",
      "Auto-scaling: Enabled (1-2 instances)\n"
     ]
    }
   ],
   "source": [
    "if model_package_arn:\n",
    "    # Endpoint configuration name\n",
    "    endpoint_config_name = f\"qwen3-0-6b-lora-config-{timestamp}\"\n",
    "    \n",
    "    # Create endpoint configuration\n",
    "    # Using ml.g5.2xlarge for inference (1 GPU, 24GB memory)\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'VariantName': 'AllTraffic',\n",
    "                'ModelName': model_name,\n",
    "                'InstanceType': 'ml.g5.2xlarge',\n",
    "                'InitialInstanceCount': 1,\n",
    "                'InitialVariantWeight': 1,\n",
    "                'ManagedInstanceScaling': {\n",
    "                    'Status': 'ENABLED',\n",
    "                    'MinInstanceCount': 1,\n",
    "                    'MaxInstanceCount': 1\n",
    "                },\n",
    "                'RoutingConfig': {\n",
    "                    'RoutingStrategy': 'LEAST_OUTSTANDING_REQUESTS'\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        Tags=[\n",
    "            {'Key': 'Project', 'Value': 'MLOps-Workshop'},\n",
    "            {'Key': 'Model', 'Value': 'QWEN3-0.6B'},\n",
    "            {'Key': 'Type', 'Value': 'Inference'}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Endpoint Configuration Created ===\")\n",
    "    print(f\"Config Name: {endpoint_config_name}\")\n",
    "    print(f\"Config ARN: {endpoint_config_response['EndpointConfigArn']}\")\n",
    "    print(f\"Instance Type: ml.g5.2xlarge\")\n",
    "    print(f\"Initial Instance Count: 1\")\n",
    "    print(f\"Auto-scaling: Enabled (1-2 instances)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:51:57.832158Z",
     "iopub.status.busy": "2025-08-31T12:51:57.831912Z",
     "iopub.status.idle": "2025-08-31T12:51:58.451739Z",
     "shell.execute_reply": "2025-08-31T12:51:58.451266Z",
     "shell.execute_reply.started": "2025-08-31T12:51:57.832140Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Endpoint ===\n",
      "Endpoint Name: qwen3-0-6b-lora-endpoint-20250831-125155\n",
      "Endpoint ARN: arn:aws:sagemaker:us-east-1:637423390840:endpoint/qwen3-0-6b-lora-endpoint-20250831-125155\n",
      "Status: Creating...\n",
      "\n",
      "This process will take 5-10 minutes. You can monitor progress in the SageMaker console.\n"
     ]
    }
   ],
   "source": [
    "if model_package_arn:\n",
    "    # Endpoint name\n",
    "    endpoint_name = f\"qwen3-0-6b-lora-endpoint-{timestamp}\"\n",
    "    \n",
    "    # Create endpoint\n",
    "    create_endpoint_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        Tags=[\n",
    "            {'Key': 'Project', 'Value': 'MLOps-Workshop'},\n",
    "            {'Key': 'Model', 'Value': 'QWEN3-0.6B'},\n",
    "            {'Key': 'DeploymentType', 'Value': 'RealTime'}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Creating Endpoint ===\")\n",
    "    print(f\"Endpoint Name: {endpoint_name}\")\n",
    "    print(f\"Endpoint ARN: {create_endpoint_response['EndpointArn']}\")\n",
    "    print(f\"Status: Creating...\")\n",
    "    print(f\"\\nThis process will take 5-10 minutes. You can monitor progress in the SageMaker console.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Wait for Endpoint to be Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:51:59.511587Z",
     "iopub.status.busy": "2025-08-31T12:51:59.511342Z",
     "iopub.status.idle": "2025-08-31T12:57:00.921696Z",
     "shell.execute_reply": "2025-08-31T12:57:00.921171Z",
     "shell.execute_reply.started": "2025-08-31T12:51:59.511568Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for endpoint to be in service...\n",
      "\n",
      "=== Endpoint Deployment Successful ===\n",
      "Endpoint Name: qwen3-0-6b-lora-endpoint-20250831-125155\n",
      "Status: InService\n",
      "Created: 2025-08-31 12:51:58.403000+00:00\n"
     ]
    }
   ],
   "source": [
    "if model_package_arn:\n",
    "    # Wait for endpoint to be in service\n",
    "    print(\"Waiting for endpoint to be in service...\")\n",
    "    \n",
    "    waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "    \n",
    "    try:\n",
    "        waiter.wait(\n",
    "            EndpointName=endpoint_name,\n",
    "            WaiterConfig={\n",
    "                'Delay': 30,  # Check every 30 seconds\n",
    "                'MaxAttempts': 40  # Maximum 20 minutes\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Get endpoint status\n",
    "        endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        \n",
    "        print(f\"\\n=== Endpoint Deployment Successful ===\")\n",
    "        print(f\"Endpoint Name: {endpoint_name}\")\n",
    "        print(f\"Status: {endpoint_response['EndpointStatus']}\")\n",
    "        print(f\"Created: {endpoint_response['CreationTime']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error waiting for endpoint: {e}\")\n",
    "        print(\"Please check the endpoint status in the SageMaker console.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:57:00.922650Z",
     "iopub.status.busy": "2025-08-31T12:57:00.922449Z",
     "iopub.status.idle": "2025-08-31T12:57:01.588796Z",
     "shell.execute_reply": "2025-08-31T12:57:01.588306Z",
     "shell.execute_reply.started": "2025-08-31T12:57:00.922633Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Endpoint ===\n",
      "\n",
      "Note: If you get a timeout error, the model might still be loading.\n",
      "Wait a few minutes and try again, or check CloudWatch logs for details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model_package_arn:\n",
    "    # Create a predictor for the endpoint\n",
    "    from sagemaker.predictor import Predictor\n",
    "    \n",
    "    predictor = Predictor(\n",
    "        endpoint_name=endpoint_name,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=JSONDeserializer()\n",
    "    )\n",
    "    \n",
    "    print(\"=== Testing Endpoint ===\")\n",
    "    print(\"\\nNote: If you get a timeout error, the model might still be loading.\")\n",
    "    print(\"Wait a few minutes and try again, or check CloudWatch logs for details.\\n\")\n",
    "    \n",
    "    # Start with a simple test\n",
    "    simple_test = {\n",
    "        \"inputs\": \"Hi!\",\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 10,\n",
    "            \"temperature\": 0.1,\n",
    "            \"do_sample\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = predictor.predict(\n",
    "        data=simple_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:57:01.589593Z",
     "iopub.status.busy": "2025-08-31T12:57:01.589334Z",
     "iopub.status.idle": "2025-08-31T12:57:01.593190Z",
     "shell.execute_reply": "2025-08-31T12:57:01.592735Z",
     "shell.execute_reply.started": "2025-08-31T12:57:01.589568Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': 'I need help with this problem. The problem is'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Monitor Endpoint Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:58:09.247537Z",
     "iopub.status.busy": "2025-08-31T12:58:09.247287Z",
     "iopub.status.idle": "2025-08-31T12:58:09.253913Z",
     "shell.execute_reply": "2025-08-31T12:58:09.253470Z",
     "shell.execute_reply.started": "2025-08-31T12:58:09.247517Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Available CloudWatch Metrics ===\n",
      "Namespace: AWS/SageMaker\n",
      "Endpoint: qwen3-0-6b-lora-endpoint-20250831-125155\n",
      "\n",
      "Key metrics to monitor:\n",
      "- ModelLatency: Time taken for model inference\n",
      "- OverheadLatency: Time taken by SageMaker overhead\n",
      "- Invocations: Number of InvokeEndpoint requests\n",
      "- Invocation4XXErrors: Number of 4XX errors\n",
      "- Invocation5XXErrors: Number of 5XX errors\n",
      "- ModelSetupTime: Time to load the model\n",
      "\n",
      "You can view these metrics in the CloudWatch console.\n"
     ]
    }
   ],
   "source": [
    "if model_package_arn:\n",
    "    # Get CloudWatch metrics\n",
    "    cloudwatch_client = boto3.client('cloudwatch', region_name=region)\n",
    "    \n",
    "    print(\"\\n=== Available CloudWatch Metrics ===\")\n",
    "    print(f\"Namespace: AWS/SageMaker\")\n",
    "    print(f\"Endpoint: {endpoint_name}\")\n",
    "    print(\"\\nKey metrics to monitor:\")\n",
    "    print(\"- ModelLatency: Time taken for model inference\")\n",
    "    print(\"- OverheadLatency: Time taken by SageMaker overhead\")\n",
    "    print(\"- Invocations: Number of InvokeEndpoint requests\")\n",
    "    print(\"- Invocation4XXErrors: Number of 4XX errors\")\n",
    "    print(\"- Invocation5XXErrors: Number of 5XX errors\")\n",
    "    print(\"- ModelSetupTime: Time to load the model\")\n",
    "    print(\"\\nYou can view these metrics in the CloudWatch console.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Endpoint Information Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:58:20.267838Z",
     "iopub.status.busy": "2025-08-31T12:58:20.267569Z",
     "iopub.status.idle": "2025-08-31T12:58:20.272435Z",
     "shell.execute_reply": "2025-08-31T12:58:20.271977Z",
     "shell.execute_reply.started": "2025-08-31T12:58:20.267816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Deployment Summary ===\n",
      "Endpoint Name: qwen3-0-6b-lora-endpoint-20250831-125155\n",
      "Model Package: 5\n",
      "Instance Type: ml.g5.2xlarge\n",
      "Auto-scaling: 1-2 instances\n",
      "Region: us-east-1\n",
      "\n",
      "Endpoint information saved to 'endpoint_info.json'\n",
      "\n",
      "=== How to Invoke the Endpoint ===\n",
      "You can invoke this endpoint using:\n",
      "1. SageMaker SDK (as shown above)\n",
      "2. AWS SDK (boto3)\n",
      "3. AWS CLI\n",
      "4. HTTP API with SigV4 authentication\n"
     ]
    }
   ],
   "source": [
    "if model_package_arn:\n",
    "    # Save endpoint information for future use\n",
    "    endpoint_info = {\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"model_name\": model_name,\n",
    "        \"model_package_arn\": model_package_arn,\n",
    "        \"instance_type\": \"ml.g5.2xlarge\",\n",
    "        \"created_time\": timestamp,\n",
    "        \"region\": region\n",
    "    }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open('endpoint_info.json', 'w') as f:\n",
    "        json.dump(endpoint_info, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"\\n=== Deployment Summary ===\")\n",
    "    print(f\"Endpoint Name: {endpoint_name}\")\n",
    "    print(f\"Model Package: {model_package_arn.split('/')[-1]}\")\n",
    "    print(f\"Instance Type: ml.g5.2xlarge\")\n",
    "    print(f\"Auto-scaling: 1-2 instances\")\n",
    "    print(f\"Region: {region}\")\n",
    "    print(\"\\nEndpoint information saved to 'endpoint_info.json'\")\n",
    "    print(\"\\n=== How to Invoke the Endpoint ===\")\n",
    "    print(\"You can invoke this endpoint using:\")\n",
    "    print(\"1. SageMaker SDK (as shown above)\")\n",
    "    print(\"2. AWS SDK (boto3)\")\n",
    "    print(\"3. AWS CLI\")\n",
    "    print(\"4. HTTP API with SigV4 authentication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Clean Up Resources (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T12:58:29.115509Z",
     "iopub.status.busy": "2025-08-31T12:58:29.115258Z",
     "iopub.status.idle": "2025-08-31T12:58:29.119664Z",
     "shell.execute_reply": "2025-08-31T12:58:29.119091Z",
     "shell.execute_reply.started": "2025-08-31T12:58:29.115490Z"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Only run this cell when you want to delete the endpoint\n",
    "# This will incur no further charges\n",
    "\n",
    "def cleanup_resources(endpoint_name, endpoint_config_name, model_name):\n",
    "    \"\"\"\n",
    "    Clean up SageMaker resources to avoid charges.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Delete endpoint\n",
    "        print(f\"Deleting endpoint: {endpoint_name}\")\n",
    "        sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(\"Endpoint deletion initiated.\")\n",
    "        \n",
    "        # Wait for endpoint to be deleted\n",
    "        time.sleep(30)\n",
    "        \n",
    "        # Delete endpoint configuration\n",
    "        print(f\"Deleting endpoint configuration: {endpoint_config_name}\")\n",
    "        sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "        print(\"Endpoint configuration deleted.\")\n",
    "        \n",
    "        # Delete model\n",
    "        print(f\"Deleting model: {model_name}\")\n",
    "        sm_client.delete_model(ModelName=model_name)\n",
    "        print(\"Model deleted.\")\n",
    "        \n",
    "        print(\"\\n=== Cleanup Complete ===\")\n",
    "        print(\"All resources have been deleted.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "        print(\"Some resources may need to be manually deleted from the SageMaker console.\")\n",
    "\n",
    "# Uncomment the following lines to delete resources:\n",
    "# if model_package_arn:\n",
    "#     cleanup_resources(endpoint_name, endpoint_config_name, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you have successfully deployed the model to a SageMaker endpoint:\n",
    "\n",
    "1. **Integration**: Integrate the endpoint with your applications using AWS SDKs\n",
    "2. **Monitoring**: Set up CloudWatch alarms for endpoint metrics\n",
    "3. **A/B Testing**: Deploy multiple model variants for comparison\n",
    "4. **Pipeline Integration**: Include this deployment in your SageMaker Pipeline\n",
    "5. **Cost Optimization**: Consider using SageMaker Multi-Model Endpoints or Serverless Inference for cost savings\n",
    "\n",
    "The endpoint is now ready to serve real-time predictions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
