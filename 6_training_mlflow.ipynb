{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QWEN3-0.6B LoRA Fine-tuning with MLflow Tracking\n",
    "\n",
    "This notebook demonstrates how to fine-tune QWEN3-0.6B using LoRA on Amazon SageMaker with MLflow tracking integration.\n",
    "\n",
    "## MLflow Integration\n",
    "\n",
    "MLflow tracking allows you to:\n",
    "- Track training parameters and hyperparameters\n",
    "- Log training metrics (loss, evaluation metrics) in real-time\n",
    "- Store model artifacts and configurations\n",
    "- Compare different training runs\n",
    "- Visualize training progress through the MLflow UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade SageMaker SDK to use PyTorch 2.7.1 for training job\n",
    "# !pip install --upgrade sagemaker mlflow sagemaker-mlflow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure SageMaker Session and Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# IAM role - Update this to your role\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"Using SageMaker execution role: {role}\")\n",
    "\n",
    "# S3 Bucket (default bucket)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"qwen3-0-6-lora-samples-mlflow\"\n",
    "\n",
    "print(f\"Using bucket: {bucket}\")\n",
    "print(f\"Using prefix: {prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure MLflow Tracking Server\n",
    "\n",
    "Configure the MLflow tracking server to record experiment data. The tracking server stores:\n",
    "- Training parameters and hyperparameters\n",
    "- Metrics logged during training\n",
    "- Model artifacts and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow tracking server configuration\n",
    "mlflow_tracking_server_arn = \"arn:aws:sagemaker:us-east-1:418272795925:mlflow-tracking-server/mlflow-test\"\n",
    "mlflow_experiment_name = \"qwen3-lora-training\"\n",
    "\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "print(f\"MLflow Experiment Name: {mlflow_experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload Local Sample Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload local train.jsonl data to S3\n",
    "print(\"Uploading train.jsonl data to S3...\")\n",
    "train_s3_uri = sagemaker_session.upload_data(\n",
    "    path='samples/train.jsonl',\n",
    "    bucket=bucket,\n",
    "    key_prefix=f'{prefix}/data/train'\n",
    ")\n",
    "print(f\"Training data uploaded to: {train_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "exp_name = 'qwen3-0-6b-lora-fine-tuning-mlflow'\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "\n",
    "# Output paths\n",
    "output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "checkpoint_s3_uri = f\"s3://{bucket}/{prefix}/checkpoints\"\n",
    "\n",
    "# Job name based on timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "job_name = f\"{exp_name}-{timestamp}\"\n",
    "\n",
    "print(f\"Job name: {job_name}\")\n",
    "print(f\"Output path: {output_path}\")\n",
    "print(f\"Checkpoint path: {checkpoint_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define Hyperparameters\n",
    "\n",
    "These hyperparameters control:\n",
    "- **Model**: Base model and configuration\n",
    "- **Training**: Learning rate, batch size, epochs, etc.\n",
    "- **LoRA**: Low-Rank Adaptation parameters for efficient fine-tuning\n",
    "- **MLflow**: Tracking server and experiment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "hyperparameters = {\n",
    "    # Model\n",
    "    \"model_name_or_path\": \"Qwen/Qwen3-0.6B\",\n",
    "    \n",
    "    # Training (HuggingFace TrainingArguments)\n",
    "    \"output_dir\": \"/opt/ml/model\",\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 64,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_ratio\": 0.03,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"logging_steps\": 1,\n",
    "    \"save_steps\": 1,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_total_limit\": 3,\n",
    "    \"do_eval\": True,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 50,\n",
    "    \"metric_for_best_model\": \"eval_loss\",\n",
    "    \"greater_is_better\": False,\n",
    "    \"load_best_model_at_end\": False,\n",
    "    \"report_to\": \"none\",  # We're using MLflow instead\n",
    "    \"bf16\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \n",
    "    # LoRA\n",
    "    \"lora_r\": 4, \n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"lora_target_modules\": \"q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj\",\n",
    "    \n",
    "    # Dataset\n",
    "    \"train_file\": \"/opt/ml/input/data/train/train.jsonl\",\n",
    "    \"validation_split_percentage\": 20,\n",
    "    \"block_size\": 256,\n",
    "    \n",
    "    # MLflow Configuration\n",
    "    \"mlflow_tracking_server_arn\": mlflow_tracking_server_arn,\n",
    "    \"mlflow_experiment_name\": mlflow_experiment_name,\n",
    "}\n",
    "\n",
    "print(\"Hyperparameters configured successfully\")\n",
    "print(f\"\\nMLflow tracking enabled: {hyperparameters.get('mlflow_tracking_server_arn') is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create PyTorch Estimator\n",
    "\n",
    "**Important**: This estimator uses `train_mlflow.py` which includes MLflow integration for tracking experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Estimator with MLflow-enabled training script\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_with_mlflow.py\",  # MLflow-enabled training script\n",
    "    source_dir=\"src\",\n",
    "    role=role,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    framework_version=\"2.7.1\",  \n",
    "    py_version=\"py312\",  \n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=output_path,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    use_spot_instances=False,  \n",
    "    max_run=24*60*60,  # Maximum 24 hours\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    volume_size=450,\n",
    "    environment={\n",
    "        \"PYTORCH_CUDA_ALLOC_CONF\": \"expandable_segments:True\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"PyTorch estimator created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prepare Training Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data input - using train.jsonl\n",
    "train_input = TrainingInput(\n",
    "    s3_data=train_s3_uri,\n",
    "    content_type=\"application/jsonl\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    distribution=\"FullyReplicated\"\n",
    ")\n",
    "\n",
    "print(f\"Training input configured with data from: {train_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Start Training Job\n",
    "\n",
    "This will submit the training job to SageMaker. The training script will:\n",
    "1. Connect to the MLflow tracking server\n",
    "2. Create a new experiment run\n",
    "3. Log all hyperparameters\n",
    "4. Log training and evaluation metrics in real-time\n",
    "5. Save model artifacts to both S3 and MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training job\n",
    "print(f\"Starting training job: {job_name}\")\n",
    "print(f\"Training data: {train_s3_uri}\")\n",
    "print(f\"Note: The training script will automatically split train.jsonl - {100-hyperparameters['validation_split_percentage']}% for training, {hyperparameters['validation_split_percentage']}% for validation\")\n",
    "print(f\"\\nMLflow Experiment: {mlflow_experiment_name}\")\n",
    "print(f\"MLflow Tracking Server: {mlflow_tracking_server_arn}\")\n",
    "\n",
    "estimator.fit(\n",
    "    inputs={\n",
    "        \"train\": train_input\n",
    "    },\n",
    "    job_name=job_name,\n",
    "    wait=False  # Asynchronous start\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining job '{job_name}' has been submitted!\")\n",
    "print(f\"You can monitor the job in the SageMaker console\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Monitor Training Progress\n",
    "\n",
    "You can monitor the training job in multiple ways:\n",
    "\n",
    "### SageMaker Console\n",
    "View the training job logs and status in the [SageMaker Console](https://console.aws.amazon.com/sagemaker/home#/jobs)\n",
    "\n",
    "### MLflow UI\n",
    "Access the MLflow tracking UI through SageMaker Studio to:\n",
    "- View real-time training metrics\n",
    "- Compare different runs\n",
    "- Inspect logged parameters and artifacts\n",
    "\n",
    "To access MLflow UI:\n",
    "1. Go to SageMaker Studio\n",
    "2. Navigate to the MLflow tracking server\n",
    "3. Open the MLflow UI\n",
    "4. Find your experiment: `qwen3-lora-training`\n",
    "5. Click on the run to view details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Wait for the training job to complete\n",
    "# Uncomment the line below if you want to wait for the job to finish\n",
    "# estimator.latest_training_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Retrieve Training Job Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training job name\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training Job Name: {training_job_name}\")\n",
    "\n",
    "# Get model artifact location\n",
    "# Note: This will only work after the training job completes\n",
    "try:\n",
    "    model_data = estimator.model_data\n",
    "    print(f\"Model artifacts location: {model_data}\")\n",
    "except:\n",
    "    print(\"Model artifacts will be available after training completes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. View MLflow Experiment Results\n",
    "\n",
    "Once the training job starts, you can view the results in MLflow:\n",
    "\n",
    "### Logged Information\n",
    "\n",
    "The training script logs the following to MLflow:\n",
    "\n",
    "**Parameters:**\n",
    "- Model name and configuration\n",
    "- LoRA hyperparameters (r, alpha, dropout, target modules)\n",
    "- Training hyperparameters (learning rate, batch size, epochs, etc.)\n",
    "- Dataset configuration (block size, split percentage, dataset sizes)\n",
    "\n",
    "**Metrics:**\n",
    "- Training loss (per step)\n",
    "- Evaluation loss (per eval step)\n",
    "- Learning rate (per step)\n",
    "\n",
    "**Artifacts:**\n",
    "- LoRA configuration file\n",
    "- Model checkpoints\n",
    "- Training logs\n",
    "\n",
    "### Accessing MLflow UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set tracking URI\n",
    "mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "\n",
    "# Get experiment\n",
    "experiment = mlflow.get_experiment_by_name(mlflow_experiment_name)\n",
    "print(f\"Experiment ID: {experiment.experiment_id}\")\n",
    "\n",
    "# List recent runs\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], order_by=[\"start_time DESC\"], max_results=5)\n",
    "print(runs[['run_id', 'start_time', 'status', 'tags.mlflow.runName']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. **Configure MLflow tracking** with SageMaker managed MLflow tracking server\n",
    "2. **Launch a training job** that automatically logs experiments to MLflow\n",
    "3. **Track training progress** through both SageMaker and MLflow interfaces\n",
    "4. **Log comprehensive metadata** including parameters, metrics, and artifacts\n",
    "\n",
    "### Key Benefits of MLflow Integration\n",
    "\n",
    "- **Experiment Tracking**: Automatically track all training runs with parameters and metrics\n",
    "- **Reproducibility**: All hyperparameters and configurations are logged for easy reproduction\n",
    "- **Comparison**: Compare different training runs side-by-side in the MLflow UI\n",
    "- **Collaboration**: Share experiment results with team members through a centralized tracking server\n",
    "- **Model Registry**: Seamlessly transition to model registration and deployment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "After training completes:\n",
    "1. Review training metrics in the MLflow UI\n",
    "2. Compare with other training runs to identify best hyperparameters\n",
    "3. Register the best model to MLflow Model Registry\n",
    "4. Deploy the model for inference using SageMaker endpoints\n",
    "\n",
    "For more information:\n",
    "- [SageMaker MLflow Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html)\n",
    "- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)\n",
    "- [SageMaker Training Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
